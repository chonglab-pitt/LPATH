{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec06693",
   "metadata": {},
   "source": [
    "# Example WE Notebook for lpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e05d9c",
   "metadata": {},
   "source": [
    "This notebook details steps towards running the whole lpath analysis with an MD simulation. Check our [Sphinx documentation](https://lpath.readthedocs.io) for more up-to-date information about each function.\n",
    "\n",
    "By Jeremy Leung\n",
    "Last updated: May 17th, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "634897a1c133006b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea56d538ade5d500"
  },
  {
   "cell_type": "markdown",
   "id": "5367e35d",
   "metadata": {},
   "source": [
    "## Common cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382125e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for all steps\n",
    "import argparse\n",
    "import numpy\n",
    "from lpath import discretize, extract, match, lpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b6dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97319650",
   "metadata": {},
   "source": [
    "## Discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd15f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to assign states. In this example,\n",
    "# input_array is a two column dataset: one for Phi, other for Phi.\n",
    "def assign_dih(input_array):\n",
    "    \"\"\"\n",
    "    This is an example function for mapping a list of features to state IDs. This should be subclassed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : numpy.ndarray\n",
    "        An array generated from load_file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    state_list : list\n",
    "        A list containing\n",
    "    \"\"\"\n",
    "    state_list = []\n",
    "    for val in input_array:\n",
    "        if val[0] >= -180 and val[0] <= -45 and val[1] >= -55 and val[1] <= 30:  # Phi/Psi for Alpha Helix\n",
    "            state_list.append(0)\n",
    "        elif val[0] >= 165 and val[0] <= 180 and val[1] >= -55 and val[1] <= 30:\n",
    "            state_list.append(0)\n",
    "        elif val[0] >= -170 and val[0] <= -55 and val[1] >= 40 and val[1] <= 100:  # Phi/Psi for C7eq\n",
    "            state_list.append(1)\n",
    "        elif val[0] >= 25 and val[0] <= 90 and val[1] >= -55 and val[1] <= 0:  # Phi/Psi for C7ax\n",
    "            state_list.append(2)\n",
    "        else:\n",
    "            state_list.append(-1)\n",
    "\n",
    "    return state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for `discretize` step.\n",
    "discretize_args = argparse.Namespace(\n",
    "    we=False,  # Doing standard simulations\n",
    "    stride=1,  # Loading at stride=1. Increase to add more frames.\n",
    "    stats=True,  # Output results statistics\n",
    "    debug=False,  # Debug mode\n",
    "    out_dir='succ_traj',  # Name of directory to output the trajectories\n",
    "    input_name='dihedral.npy',  # Input data for state assignment. Something like 'dihedral.npy'.\n",
    "    extract_input='states.npy',  # Output file name for the state assignment.\n",
    "    assign_func='assign_dih',  # Assign function that dictates how to assign states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run discretize with the parameters defined in the cell above.\n",
    "discretize.main(discretize_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adaa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e264d50d",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the `extract` step.\n",
    "extract_args = argparse.Namespace(\n",
    "    we=False,  # Doing standard simulations\n",
    "    stride=1,  # Loading at stride=1. Increase to add more frames.\n",
    "    stats=True,  # Output results statistics\n",
    "    debug=False,  # Debug mode\n",
    "    out_dir='succ_traj',  # Name of directory to output the trajectories\n",
    "    extract_input='states.npy',  # Name of input assign.h5 file\n",
    "    extract_output='succ_traj/output.pickle',  # Name of input assign.h5 file\n",
    "\n",
    "    source_state_num=0,  # Index of the source state as defined in assign_name.\n",
    "    target_state_num=1,  # Index of the target state as defined in assign_name.\n",
    "    pcoord=False,  # Option to output extra datasets\n",
    "    featurization_name='states.npy',  # Specify a file name if pcoord=True \n",
    "    feature_stride=1,  # Option to stride `pcoord`\n",
    "    exclude_short=0,  # Exclude trajectories shorter than provided value during matching. 0 excludes none.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run match with the parameters defined in the cell above.\n",
    "extract.main(extract_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291c641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aef8e77",
   "metadata": {},
   "source": [
    "## Pattern Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define function to assign states. In this example,\n",
    "# input_array is a two column dataset: one for Phi, other for Phi.\n",
    "def assign_dih(input_array):\n",
    "    \"\"\"\n",
    "    This is an example function for mapping a list of features to state IDs. This should be subclassed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : numpy.ndarray\n",
    "        An array generated from load_file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    state_list : list\n",
    "        A list containing\n",
    "    \"\"\"\n",
    "    state_list = []\n",
    "    for val in input_array:\n",
    "        if val[0] >= -180 and val[0] <= -45 and val[1] >= -55 and val[1] <= 30:  # Phi/Psi for Alpha Helix\n",
    "            state_list.append(0)\n",
    "        elif val[0] >= 165 and val[0] <= 180 and val[1] >= -55 and val[1] <= 30:\n",
    "            state_list.append(0)\n",
    "        elif val[0] >= -170 and val[0] <= -55 and val[1] >= 40 and val[1] <= 100:  # Phi/Psi for C7eq\n",
    "            state_list.append(1)\n",
    "        elif val[0] >= 25 and val[0] <= 90 and val[1] >= -55 and val[1] <= 0:  # Phi/Psi for C7ax\n",
    "            state_list.append(2)\n",
    "        else:\n",
    "            state_list.append(-1)\n",
    "\n",
    "    return state_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24893b35f433f49e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to group assigned states. In this example,\n",
    "# input_array is a two column dataset: one for Phi, other for Phi.\n",
    "def reassign_custom(data, pathways, dictionary, assign_file=None):\n",
    "    \"\"\"\n",
    "    Reclassify/assign frames into different states. This is highly\n",
    "    specific to the system. If w_assign's definition is suffcient,\n",
    "    you can proceed with what's made in the previous step\n",
    "    using `reassign_identity`.\n",
    "\n",
    "    In this example, the dictionary maps state idx to its corresponding `state_string`.\n",
    "    I suggest using alphabets as states.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        An array with the data necessary to reassign, as extracted from `output.pickle`.\n",
    "\n",
    "    pathways : numpy.ndarray\n",
    "        An empty array with shapes for iter_id/seg_id/state_id/pcoord_or_auxdata/weight.\n",
    "\n",
    "    dictionary : dict\n",
    "        An empty dictionary obj for mapping `state_id` with `state string`.\n",
    "\n",
    "    assign_file : str, default : None\n",
    "        A string pointing to the assign.h5 file. Needed as a parameter for all functions,\n",
    "        but is ignored if it's an MD trajectory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary : dict\n",
    "        A dictionary mapping each state_id (float/int) with a `state string` (character).\n",
    "    \"\"\"\n",
    "    # Other example for grouping multiple states into one.\n",
    "    for idx, val in enumerate(data):\n",
    "        # The following shows how you can \"merge\" multiple states into\n",
    "        # a single one.\n",
    "        flipped_val = numpy.asarray(val)[::-1]\n",
    "        first_contact = numpy.where(flipped_val[:, 3] < 5)[0][0]\n",
    "        for idx2, val2 in enumerate(flipped_val):\n",
    "            # ortho is assigned to state 0\n",
    "            if val2[2] in [1, 3, 4, 6, 7, 9]:\n",
    "                val2[2] = 0\n",
    "            # para is assigned to state 1\n",
    "            elif val2[2] in [2, 5, 8]:\n",
    "                val2[2] = 1\n",
    "            # Unknown state is assigned 2\n",
    "            if idx2 < first_contact:\n",
    "                val2[2] = 2\n",
    "            pathways[idx, idx2] = val2\n",
    "\n",
    "    # Generating a dictionary mapping each state\n",
    "    dictionary = {0: 'A', 1: 'B', 2: '!'}\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the `match` step.\n",
    "match_args = argparse.Namespace(\n",
    "    we=False,  # Doing standard simulations\n",
    "    stride=1,  # Loading at stride=1. Increase to add more frames.\n",
    "    out_dir='succ_traj',  # Output for the distance Matrix\n",
    "    extract_output='succ_traj/output.pickle',  # Input file name of the pickle from `extract.py`\n",
    "    output_pickle='succ_traj/pathways.pickle',  # Output file name of the new reassigned pathways from `lpath.match`\n",
    "    reassign_method='reassign_custom',  # Reassign method. Could be a module to be loaded.\n",
    "    match_metric='longest_common_subsequence',  # Use the longest common subsequence metric.\n",
    "    match_vanilla=False, # Whether to use the metric with a correction term\n",
    "    dmatrix_remake=True,  # Enable to remake the distance Matrix\n",
    "    dmatrix_save='succ_traj/distmat.npy',  # If dmatrix_remake is False, load this file instead.\n",
    "    dmatrix_parallel=-1,  # Number of jobs to submit for distance matrix calculation. Set to -1 to use everything.\n",
    "    dendrogram_threshold=0.5,  # Threshold for the Dendrogram\n",
    "    dendrogram_show=True,  # Show the Dendrogram using plt.show()\n",
    "    cl_output='succ_traj/cluster_labels.npy',  # Output path for cluster labels\n",
    "    clusters=None,  # Cluster index to output... otherwise None --> All\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f148c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run discretize with the parameters defined in the cell above.\n",
    "match.main(match_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67402a920f7ffe00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run All"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ae15a65569223f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For calling all steps directly. Note all parameters are specified manually here.\n",
    "import argparse\n",
    "from lpath.lpath import main\n",
    "\n",
    "all_args = argparse.Namespace(\n",
    "    # Common Parameters\n",
    "    out_dir=\"succ_traj\",  # Name of directory to output the trajectories.\n",
    "    debug=False,  # Debug mode\n",
    "    we=False,  # Not analyzing a WE simulation.\n",
    "    stats=True,  # Output results statistics\n",
    "    stride=1,  # Loading at stride=1. Increase to add more frames.\n",
    "\n",
    "    # Discretize Parameters\n",
    "    input_name='dihedral.npy',  # Input data for state assignment. Something like 'dihedral.npy'.\n",
    "    extract_input='states.npy',  # Output file name for the state assignment.\n",
    "    assign_func='assign_dih',  # Assign function that dictates how to assign states\n",
    " \n",
    "    # Extract Parameters\n",
    "    # Note west_name and assign_name are repeated from above and removed\n",
    "    extract_output='succ_traj/output.pickle',  # Name of input assign.h5 file\n",
    "    source_state_num=0,  # Index of the source state as defined in assign_name.\n",
    "    target_state_num=1,  # Index of the target state as defined in assign_name.\n",
    "    pcoord=False,  # Option to output extra datasets\n",
    "    featurization_name='states.npy',  # Specify a file name if pcoord=True \n",
    "    feature_stride=1,  # Option to stride `pcoord`\n",
    "    exclude_short=0,  # Exclude trajectories shorter than provided value during matching. 0 excludes none.\n",
    "\n",
    "    # Match Parameters\n",
    "    # Note west_name, assign_name and out_dir are repeated from above and removed\n",
    "    output_pickle='succ_traj/pathways.pickle',  # Output file name of the new reassigned pathways from `lpath.match`\n",
    "    reassign_method='reassign_custom',  # Reassign method. Could be a module to be loaded.\n",
    "    match_metric='longest_common_subsequence',  # Use the longest common subsequence metric.\n",
    "    match_vanilla=False, # Whether to use the metric with a correction term\n",
    "    dmatrix_remake=True,  # Enable to remake the distance Matrix\n",
    "    dmatrix_save='succ_traj/distmat.npy',  # If dmatrix_remake is False, load this file instead.\n",
    "    dmatrix_parallel=-1,  # Number of jobs to submit for distance matrix calculation. Set to -1 to use everything.\n",
    "    dendrogram_threshold=0.5,  # Threshold for the Dendrogram\n",
    "    dendrogram_show=True,  # Show the Dendrogram using plt.show()\n",
    "    cl_output='succ_traj/cluster_labels.npy',  # Output path for cluster labels\n",
    "    clusters=None,  # Cluster index to output... otherwise None --> All\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc5a66d972080cc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lpath.main(all_args)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d81e3ac09b689ccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a3a919c55bc15ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
